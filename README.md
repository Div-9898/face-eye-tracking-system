# ğŸ‘ï¸ Face & Eye Tracking System

A real-time face and eye tracking application built with Python, Streamlit, and MediaPipe. This system provides advanced facial monitoring capabilities with eye movement detection, blink counting, and comprehensive analytics.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## âœ¨ Features

- **Real-time Face Detection**: Accurate face tracking using MediaPipe's advanced AI models
- **Eye Movement Tracking**: Detects both eyes individually with Eye Aspect Ratio (EAR) calculations
- **Blink Detection**: Counts blinks and monitors eye closure patterns
- **Head Pose Estimation**: Tracks pitch, yaw, and roll angles to determine gaze direction
- **Center Position Tracking**: Monitors if the face is centered in the camera frame
- **Live Analytics**: Real-time performance metrics and visualizations
- **Session Recording**: Save and export tracking data for later analysis
- **Beautiful UI**: Modern, animated interface with gradient themes

## ğŸ–¼ï¸ Screenshots

### Main Dashboard
- Real-time camera feed with face landmarks
- Live status indicators
- Performance analytics
- Eye tracking visualizations

### Features Include:
- ğŸ“Š Circular progress indicators for metrics
- ğŸ“ˆ Real-time charts for eye aspect ratios
- ğŸ¯ Distance from center tracking
- ğŸ‘€ Individual eye detection status
- ğŸ”„ Head orientation gauges

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- Webcam/Camera
- Windows/Linux/MacOS

### Setup

1. Clone the repository:
```bash
git clone https://github.com/Div-9898/face-eye-tracking-system.git
cd face-eye-tracking-system
```

2. Create a virtual environment:
```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On Linux/Mac
source venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ® Usage

### Local Usage

1. Run the application:
```bash
streamlit run Video_monitoring_app.py
```

2. Open your browser and navigate to `http://localhost:8501`

3. Grant camera permissions when prompted

4. Click "Start" to begin tracking

### ğŸŒ Deploy on Streamlit Cloud

You can also deploy this app on Streamlit Cloud for free:

1. Fork this repository to your GitHub account
2. Sign up for [Streamlit Cloud](https://streamlit.io/cloud)
3. Click "New app" and select your forked repository
4. Choose `streamlit_app.py` as the main file
5. Click "Deploy"

**Note**: Camera access in Streamlit Cloud depends on browser permissions and HTTPS. The app works best when run locally or on HTTPS-enabled domains.

### ğŸ³ Docker Deployment (Optional)

```dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && apt-get install -y \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgstreamer1.0-0 \
    libgstreamer-plugins-base1.0-0 \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "Video_monitoring_app.py"]
```

### Controls
- **â–¶ï¸ Start**: Begin face tracking session
- **â¸ï¸ Stop**: Pause tracking and save session data
- **ğŸ“¸ Snapshot**: Capture current frame (coming soon)
- **ğŸ”„ Reset**: Clear counters and data
- **ğŸšª Exit**: Close the application

### Settings
- **Center Threshold**: Adjust sensitivity for center detection
- **Blink Threshold**: Set Eye Aspect Ratio threshold for blink detection
- **Pitch/Yaw Thresholds**: Configure head pose detection sensitivity
- **Debug Mode**: Show/hide FPS and detection information
- **Show Face Landmarks**: Toggle face mesh visualization

## ğŸ“Š Metrics Explained

### Eye Aspect Ratio (EAR)
- Measures eye openness
- Values typically range from 0.1 to 0.4
- Lower values indicate closed eyes

### Head Pose Angles
- **Pitch**: Up/down head movement
- **Yaw**: Left/right head rotation
- **Roll**: Head tilt angle

### Performance Metrics
- **Face Detection Rate**: Percentage of frames with detected face
- **Centered Rate**: Time spent in center position
- **Attention Rate**: Time spent looking at camera
- **Both Eyes Rate**: Frames with both eyes detected

## ğŸ› ï¸ Technical Details

### Technologies Used
- **Streamlit**: Web application framework
- **OpenCV**: Computer vision and image processing
- **MediaPipe**: Face detection and landmark tracking
- **NumPy**: Numerical computations
- **Pandas**: Data manipulation and analysis
- **Plotly**: Interactive visualizations

### Key Components
1. **FaceTracker Class**: Core tracking logic and calculations
2. **StreamlitApp Class**: UI management and user interactions
3. **Real-time Processing**: Frame-by-frame analysis at 30 FPS
4. **Session Analytics**: Data collection and export functionality

## ğŸ“ Project Structure

```
face-eye-tracking-system/
â”‚
â”œâ”€â”€ Video_monitoring_app.py    # Main application file
â”œâ”€â”€ test_camera.py            # Camera testing utility
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                # Project documentation
â””â”€â”€ .gitignore              # Git ignore file
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- MediaPipe team for the amazing face detection models
- Streamlit for the excellent web framework
- OpenCV community for computer vision tools

## ğŸ“ Contact

GitHub: [@Div-9898](https://github.com/Div-9898)

Project Link: [https://github.com/Div-9898/face-eye-tracking-system](https://github.com/Div-9898/face-eye-tracking-system)

---

<p align="center">Made with â¤ï¸ using Python and Streamlit</p> 