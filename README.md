# üëÅÔ∏è Face & Eye Tracking System

A real-time face and eye tracking application built with Python, Streamlit, and MediaPipe. This system provides advanced facial monitoring capabilities with eye movement detection, blink counting, and comprehensive analytics.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ‚ú® Features

- **Real-time Face Detection**: Accurate face tracking using MediaPipe's advanced AI models
- **Eye Movement Tracking**: Detects both eyes individually with Eye Aspect Ratio (EAR) calculations
- **Blink Detection**: Counts blinks and monitors eye closure patterns
- **Head Pose Estimation**: Tracks pitch, yaw, and roll angles to determine gaze direction
- **Center Position Tracking**: Monitors if the face is centered in the camera frame
- **Live Analytics**: Real-time performance metrics and visualizations
- **Session Recording**: Save and export tracking data for later analysis
- **Beautiful UI**: Modern, animated interface with gradient themes

## üñºÔ∏è Screenshots

### Main Dashboard
- Real-time camera feed with face landmarks
- Live status indicators
- Performance analytics
- Eye tracking visualizations

### Features Include:
- üìä Circular progress indicators for metrics
- üìà Real-time charts for eye aspect ratios
- üéØ Distance from center tracking
- üëÄ Individual eye detection status
- üîÑ Head orientation gauges

## üöÄ Installation

### Prerequisites
- Python 3.8 or higher
- Webcam/Camera
- Windows/Linux/MacOS

### Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/face-eye-tracking-system.git
cd face-eye-tracking-system
```

2. Create a virtual environment:
```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On Linux/Mac
source venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## üéÆ Usage

1. Run the application:
```bash
streamlit run Video_monitoring_app.py
```

2. Open your browser and navigate to `http://localhost:8501`

3. Grant camera permissions when prompted

4. Click "Start" to begin tracking

### Controls
- **‚ñ∂Ô∏è Start**: Begin face tracking session
- **‚è∏Ô∏è Stop**: Pause tracking and save session data
- **üì∏ Snapshot**: Capture current frame (coming soon)
- **üîÑ Reset**: Clear counters and data
- **üö™ Exit**: Close the application

### Settings
- **Center Threshold**: Adjust sensitivity for center detection
- **Blink Threshold**: Set Eye Aspect Ratio threshold for blink detection
- **Pitch/Yaw Thresholds**: Configure head pose detection sensitivity
- **Debug Mode**: Show/hide FPS and detection information
- **Show Face Landmarks**: Toggle face mesh visualization

## üìä Metrics Explained

### Eye Aspect Ratio (EAR)
- Measures eye openness
- Values typically range from 0.1 to 0.4
- Lower values indicate closed eyes

### Head Pose Angles
- **Pitch**: Up/down head movement
- **Yaw**: Left/right head rotation
- **Roll**: Head tilt angle

### Performance Metrics
- **Face Detection Rate**: Percentage of frames with detected face
- **Centered Rate**: Time spent in center position
- **Attention Rate**: Time spent looking at camera
- **Both Eyes Rate**: Frames with both eyes detected

## üõ†Ô∏è Technical Details

### Technologies Used
- **Streamlit**: Web application framework
- **OpenCV**: Computer vision and image processing
- **MediaPipe**: Face detection and landmark tracking
- **NumPy**: Numerical computations
- **Pandas**: Data manipulation and analysis
- **Plotly**: Interactive visualizations

### Key Components
1. **FaceTracker Class**: Core tracking logic and calculations
2. **StreamlitApp Class**: UI management and user interactions
3. **Real-time Processing**: Frame-by-frame analysis at 30 FPS
4. **Session Analytics**: Data collection and export functionality

## üìÅ Project Structure

```
face-eye-tracking-system/
‚îÇ
‚îú‚îÄ‚îÄ Video_monitoring_app.py    # Main application file
‚îú‚îÄ‚îÄ test_camera.py            # Camera testing utility
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ README.md                # Project documentation
‚îî‚îÄ‚îÄ .gitignore              # Git ignore file
```

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- MediaPipe team for the amazing face detection models
- Streamlit for the excellent web framework
- OpenCV community for computer vision tools

## üìû Contact

Your Name - [@yourusername](https://twitter.com/yourusername)

Project Link: [https://github.com/yourusername/face-eye-tracking-system](https://github.com/yourusername/face-eye-tracking-system)

> **Note**: Remember to update the contact information and repository URLs with your actual GitHub username and details!

---

<p align="center">Made with ‚ù§Ô∏è using Python and Streamlit</p> 